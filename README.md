# Customer Churn Prediction Project

This project provides an end-to-end, production-ready solution for predicting customer churn at a music streaming service. The system includes data processing, model training, a REST API for inference, and a full MLOps workflow for automation and monitoring.

## Project Overview

The core objective is to identify users who are likely to cancel their subscriptions. The solution is built around a LightGBM classification model trained on user activity logs. The project emphasizes MLOps best practices, including containerization, automated testing, experiment tracking, and a strategy for model retraining and monitoring.

## Project Structure

The repository is organized into a modular structure to ensure scalability and maintainability:

-   `api/`: Contains the FastAPI application for serving predictions.
-   `configs/`: Configuration files (e.g., for model parameters).
-   `data/`: For storing raw and processed data (excluded from git).
-   `notebooks/`: Jupyter notebooks for exploratory data analysis.
-   `scripts/`: Standalone scripts for feature engineering (`featurize.py`) and model training (`train.py`).
-   `src/`: Main source code, including feature engineering logic and model code.
-   `tests/`: Unit and integration tests for the application.
-   `ml_artifacts/`: To store model artifacts generated by MLflow (excluded from git).

Key files include:
-   `pyproject.toml`: Manages Python dependencies with `uv`.
-   `Dockerfile`: Defines the container for deploying the API.
-   `Makefile`: Provides helper commands for common tasks.
-   `.pre-commit-config.yaml`: For automated code quality checks.
-   `technical_report.md`: A detailed report on the project.

## Setup and Installation

1.  **Prerequisites**:
    -   Python 3.9+
    -   Docker
    -   `make` utility

2.  **Clone the repository**:
    ```
    git clone <your-repo-url>
    cd churn-predictor
    ```

3.  **Install dependencies**:
    Create a virtual environment and install all required packages using the Makefile.
    ```
    make install
    ```
    Activate the environment:
    ```
    source .venv/bin/activate
    ```

4.  **Place data**:
    Download the `customer_churn_mini.json` dataset and place it in the `data/` directory.

## Running the Application

### 1. Training the Model

Run the feature engineering and training pipeline. This will create the processed dataset and train the model, saving the artifacts in `ml_artifacts/`.

